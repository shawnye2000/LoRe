# name of LLM model, 'custom' for custom model
llm: custom
data_name: amazon
# path for item data
item_save_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/amazon/1012_saved_item_FairAgent_ranking_MF_TFROM_start_step0_2024_repeat_1.json
# path for user data
user_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/amazon/users.json   #data/small_user.csv    #user_df.csv
selected_user_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/amazon
# selected_user_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/amazon/selected_users.json
# path for provider data
provider_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/amazon/providers.json     #data/provider_profile.json
selected_provider_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/amazon
# selected_provider_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/amazon/selected_providers.json
# path for save interaction records
profile_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/amazon/provider_profile.json
# path for save interaction records
interaction_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/data/1012_interaction_FairAgent_ranking_MF_reranking_TFROM_recency_10_2024_repeat_1.csv
# directory name for faiss index
ckpt_path: /home/chenming/mywork/study/RS/LLaMA-Factory/data/data/ckpt
index_name: /home/chenming/mywork/study/RS/LLaMA-Factory/data/data/faiss_index
# simulator directory name for saving and restoring
simulator_dir: /home/chenming/mywork/study/RS/LLaMA-Factory/data/data/simulator
# simulator restoring name
simulator_restore_file_name:
# random seed
seed: 2025  #  1. 1  2. 2025
# recommender system model
rec_model: DIN  #Pop, MF, DIN, Signal
# re-ranking system model
reranking_model: False  #TFROM   #False  #P_MMF  #FairRec  #False    #MF
tradeoff_para: 0.5 #100
# train epoch number for recommender system model
epoch_num: 20
# batch size for recommender system model
batch_size: 1024
# embedding size for recommender system model
embedding_size: 64
# learning rate for recommender system model
#lr: 0.001
# number of epochs
round: 10 # 25
# number of agents, which cannot exceed the number of user in user.csv
active_agent_threshold: 1500 #110
# method for choose agent to be active, random, sample, or marginal
agent_num:  100  #100
agent_path: True # If False, then select agent randomly, otherwise select agent from lastest file
# number of provider agents, which cannot exceed the number of providers in provider.csv
provider_agent_num:  50 # 50
provider_agent_path: True # If False, then select provider agent randomly, otherwise select agent from lastest file
# temperature for LLM
temperature: 0
# maximum number of tokens for LLM
max_token: 1500
# execution mode, serial or parallel
execution_mode: parallel  #parallel or serial  
# time interval for action of agents. The form is a number + a single letter, and the letter may be s, m, h, d, M, y
interval: 5h
# number of max retries for LLM API
max_retries: 100
# verbose mode
verbose: True
# threshold for agent num

active_method: random
# propability for agent to be active
active_prob: 0.5

active_proagent_threshold: 50
proagent_active_method: random
# implementation of agent memory, recagent or GenerativeAgentMemory
agent_memory: recagent
# list of api keys for LLM API
api_keys: EMPTY
# ratio of random recommendation, 1,3,5
rec_random_k: 0

max_item_num: 100000

#create_new_content: True

TopK: 5  # length of user recommendation list
Int_K: 20 # length of user recent interested items

item_recency: 5  #5  #5 # only recommend the most recent 5 rounds item
finetune: False #True
provider_decision_policy: consistent #full_information #CFD    #LBR  #  #LBR #full_information  #   #bounded_rational  # choosen from "random","full_information", "bounded_rational", "UWO", "PPA", "EcoAgent"
provider_lr: 0.1
provider_decision_mode: click_based
# rec hyper
lr: 0.001
weight_decay: 0.0001


max_len: 50

user_id_dim: 32
item_id_dim: 32
item_brand_id_dim: 32
item_cate_id_dim: 32

hid_units: [200, 80, 1]
dropout: 0.1

with_rec: True
with_leave: True

# dcn
mlp_hidden_size: [200, 80]
cross_layer_num: 3
dropout_prob: 0.1


# max_seq_len
max_seq_len: 20


max_workers: 10


reranking_start_step: 10

# whether have decision making under information assymetry
provider_decision_making: True

eval_agent_num: 1500

change_trust: False # True or False
ini_trust: 1.0 # 0.0~1.0

# PPO
actor_lr: 0.0001
critic_lr: 0.001


actor_user_lr: 0.0001
critic_user_lr: 0.001

gamma_user: 0.0
lmbda_user: 0.0

rec_load_checkpoint: False
rec_checkpoint_load_path: /home/chenming/mywork/study/RS/LLaMA-Factory/src/llamafactory/simulator/checkpoint/rec

ppo_load_checkpoint: True
ppo_checkpoint_load_path: /home/chenming/mywork/study/RS/LLaMA-Factory/src/llamafactory/simulator/checkpoint/ppo

rec_save_checkpoint: False
rec_checkpoint_save_path: /home/chenming/mywork/study/RS/LLaMA-Factory/src/llamafactory/simulator/checkpoint/rec

ppo_save_checkpoint: False
ppo_checkpoint_save_path: /home/chenming/mywork/study/RS/LLaMA-Factory/src/llamafactory/simulator/checkpoint/ppo


ppo_epochs_user: 5

gamma: 0.98 # 0.98
lmbda: 0.95 # 0.95
ppo_epochs: 10
eps: 0.2 #截断范围的参数

epochs: 20

signal: True
signal_policy: most_popular # RL, most_popular, most_click, creator_based
signal_user: False